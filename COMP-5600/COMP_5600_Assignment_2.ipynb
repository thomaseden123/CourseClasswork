{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "gYMPCFiaEkjI",
        "outputId": "752fab7b-22e1-4e36-8212-c2ba3447596e"
      },
      "outputs": [],
      "source": [
        "# Imported libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "\n",
        "# Uploads the WA_Fn-UseC_-Telco-Customer-Churn.csv input file\n",
        "files.upload()\n",
        "\n",
        "# Reads and writes the file using the pandas import\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# Drops the unique value of customerID\n",
        "df.drop('customerID', axis = 1, inplace = True)\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Use a default median value to fill in for missing values in numerical columns.\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median()) # TotalCharges column is numerical.\n",
        "\n",
        "# Use a default mode value to fill in for missing values in categorical columns.\n",
        "for column in df.select_dtypes(include=['object']).columns: # Any column with an object is categorical.\n",
        "    df[column] = df[column].fillna(df[column].mode()[0])\n",
        "\n",
        "# x and y variables used for target variable Churn\n",
        "x = df.drop('Churn', axis = 1)\n",
        "y = df['Churn'].map({'No': 0, 'Yes': 1})\n",
        "\n",
        "# Identifies categorical columns and numerical columns\n",
        "categorical_columns = x.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_columns = x.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessed = ColumnTransformer(transformers=[\n",
        "        ('numerical', StandardScaler(), numerical_columns),\n",
        "         ('categorical', OneHotEncoder(), categorical_columns)\n",
        "])\n",
        "\n",
        "# Function used to evaluate models with 5-fold cross-validation\n",
        "# (Accuracy, Precision, Recall, F1-Score, ROC-AUC)\n",
        "def evaluate_model(model, x, y):\n",
        "    pipeline = Pipeline(steps=[('pre', preprocessed), ('clf', model)])\n",
        "\n",
        "    # Metrics used for evaluation\n",
        "    score = {\n",
        "        'Accuracy': make_scorer(accuracy_score),\n",
        "        'Precision': make_scorer(precision_score),\n",
        "        'Recall': make_scorer(recall_score),\n",
        "        'F1-Score': make_scorer(f1_score),\n",
        "        'ROC-AUC': make_scorer(roc_auc_score)\n",
        "    }\n",
        "    model_result = {metric: cross_val_score(pipeline, x, y, cv=5, scoring=scorer).mean()\n",
        "            for metric, scorer in score.items()}\n",
        "    return model_result\n",
        "\n",
        "# The two classification models used\n",
        "log_regression_model = LogisticRegression(max_iter = 1000) # Logarithmic Regression\n",
        "nb_model = GaussianNB() # Naive Bayes\n",
        "\n",
        "results = {\n",
        "    \"Logistic Regression\": evaluate_model(log_regression_model, x, y),\n",
        "    \"Naive Bayes\": evaluate_model(nb_model, x, y)\n",
        "}\n",
        "\n",
        "# Displays styled results in a data frame\n",
        "data_frame = pd.DataFrame(results).T\n",
        "data_frame_style = data_frame.style.set_properties(**{'text-align': 'left'}).format({\n",
        "        'Accuracy': '{:.2%}',\n",
        "        'Precision': '{:.2%}',\n",
        "        'Recall': '{:.2%}',\n",
        "        'F1-Score': '{:.2%}',\n",
        "        'ROC-AUC': '{:.5f}'\n",
        "    }).set_table_styles(\n",
        "        [{'selector': 'td, th',\n",
        "          'props': [('border', '1px solid white')]}])\n",
        "display(data_frame_style)\n",
        "\n",
        "# Summary of Problem 1 in Assignment 2 - Basic Machine Learning\n",
        "\n",
        "# For this project, my goal was to implement two classification models: Logistic Regression and Naive Bayes to predict.\n",
        "# the variable 'Churn' using the Telco Customer Churn dataset presented in the csv file. I dropped the customerID column in the file,\n",
        "# changed the TotalCharges column to numeric values, and filled in its missing values using the median for\n",
        "# numerical (integer, float) columns and the mode for categorical (object) columns. Categorical columns were preprocessed\n",
        "# using a OneHotEncoder, while the numerical columns were preprocessed using a StandardScaler. These models were evaluated\n",
        "# using the following metrics for 5-fold cross-validation: Accuracy, Precision, Recall, F1-Score, and ROC-AUC. The results showed that the\n",
        "# accuracy and precision was higher in Logistic Regression, while the recall was higher in Naive Bayes, and the F1-Score\n",
        "# and ROC-AUC values for both models produced very similar results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "erxHi_Fii0O7",
        "outputId": "2e997d7f-5311-4f2b-95a1-b8262cfca069"
      },
      "outputs": [],
      "source": [
        "# Imported libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "\n",
        "# Uploads the test_image.png input file\n",
        "files.upload()\n",
        "\n",
        "# Reads and writes the image file using OpenCV\n",
        "img = cv2.imread('test_image.png')\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Input values for the reshape dimension of compressed image\n",
        "while True:\n",
        "    try:\n",
        "        reshape_dimension = int(input(\"\\nEnter the reshape dimension for this compressed image (Must be 1, 2, 3, 4): \\n\"))\n",
        "        if reshape_dimension in [1, 2, 3, 4]: # Any other value that isn't between 1 and 4 will give me an error\n",
        "            break\n",
        "        else:\n",
        "            print(\"\\nInvalid integer. Please enter 1, 2, 3, or 4.\")\n",
        "    except ValueError:\n",
        "        print(\"\\nInvalid input. Please enter an integer that is 1, 2, 3, or 4.\")\n",
        "\n",
        "# Shows the original image\n",
        "plt.figure(figsize=(11, 6))\n",
        "plt.imshow(img_rgb)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Compresses the image using k-means clustering\n",
        "def compress_image(img_array, k, reshape_dimension):\n",
        "    pixel = img_array.reshape(-1, reshape_dimension).astype(np.float32)\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
        "    kmeans.fit(pixel)\n",
        "    labels = kmeans.predict(pixel)\n",
        "    compressed_pixel = kmeans.cluster_centers_[labels].astype(np.uint8)\n",
        "    compressed_img = compressed_pixel.reshape(img_array.shape)\n",
        "    return compressed_img\n",
        "\n",
        "# Shows the image that comes up after the Mean Squared Error (MSE) is calculated\n",
        "# between the original and compressed images\n",
        "def mean_standard_error(original_img, compressed_img):\n",
        "  plt.figure(figsize=(11, 6))\n",
        "  calculation = np.mean((original_img.astype(\"float\") - compressed_img.astype(\"float\")) ** 2)\n",
        "  return calculation\n",
        "\n",
        "# Different values of k that were being used\n",
        "errors = []\n",
        "k_values = [2, 4, 8, 16, 32]\n",
        "\n",
        "# K-Value loop that calculates the MSE\n",
        "for k in k_values:\n",
        "    compressed_img = compress_image(img_rgb, k, reshape_dimension)\n",
        "    error = mean_standard_error(img_rgb, compressed_img)\n",
        "    errors.append(error)\n",
        "\n",
        "    # Shows the compressed image\n",
        "    plt.imshow(compressed_img)\n",
        "    plt.title(f'Compressed Image (K={k})')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    cv2.imwrite(f'compressed_k_{k}.png', cv2.cvtColor(compressed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Plots the number of clusters (K) vs. mean squared error (MSE)\n",
        "plt.plot(k_values, errors, marker='o')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.xticks(np.arange(0, 34, 2))\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.yticks(np.arange(0, 2100, 100))\n",
        "plt.title('Number of Clusters (K) vs. Mean Squared Error (MSE)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "results = {\n",
        "    'Number of Clusters (K)': k_values,\n",
        "    'Mean Squared Error (MSE)': errors\n",
        "}\n",
        "\n",
        "# Displays styled results in a data frame\n",
        "data_frame = pd.DataFrame(results)\n",
        "data_frame_style = data_frame.style.set_properties(**{'text-align': 'left'}).hide(axis='index').format({\n",
        "    'Number of Clusters (K)': '{:d}',\n",
        "    'Mean Squared Error (MSE)': '{:.10f}'\n",
        "}).set_table_styles(\n",
        "        [{'selector': 'td, th',\n",
        "          'props': [('border', '1px solid white')]}])\n",
        "display(data_frame_style)\n",
        "\n",
        "# Summary of Problem 2 in Assignment 2 - Basic Machine Learning\n",
        "\n",
        "# For this project, my goal was to implement a naive version of a k-means clustering algorithm to compress\n",
        "# the test_image.png file by using a limited color palette. The image was read and written using OpenCV, converted from BGR to RGB format,\n",
        "# and reshaped into pixels of a user-specified reshape dimension between 1, 2, 3 and 4 for k-means clustering. This process was tested and repeated\n",
        "# using k-values of 2, 4, 8, 16, and 32. The Mean Squared Error (MSE) was then calculated for each k-value after each compressed image relative to the original.\n",
        "# As k increased, the MSE decreased, showing that the quality of each image gradually improved and became closer to the original image.\n",
        "# The results also show that a reshape dimension of 1 has more improved quality images, while a reshape dimension of 4 has less improved quality images."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
